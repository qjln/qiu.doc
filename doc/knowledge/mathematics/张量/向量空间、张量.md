# 域上的向量空间、张量（多重线性函数定义）

## 0 前言

> 张量（tensor）这个词听得多了，但总不知所云，不妨学习一下，从向量空间开始，讲一些前期储备，到张量具体定义为止，不求甚解，提供了一些向量空间中和物理比较相关的概念、张量的一个初步印象，后面可能会继续补充一些，积累数学储备不能被数学束缚，学我所需，来去自如~

> 本文主要为Arfken写的*Mathematical Methods For Physicists*一书的读书记录。如果你在我的公众号文章中看到某本教材，大概率我是有电子版的（某些书异常罕见，占用了我不少精力和开支，当然和知识比起来不值一提），如需要可以在后台留言，我看到后会发给你用来**学习**。

> 这里前面加了个"域上的"只是为了稍微严谨一点罢了，区别于“环”、“模”什么的，忽略即可。张量有很多定义方式，多重线性函数的定义方式是比较正规和容易理解的，本文不需要太多的储备，简单的线性代数学过足矣。

## 1 向量空间

### 1.1 定义

- 一个抽象向量空间由以下几部分组成：

- [x] 一个元素称为**向量**的集合V
- [x] 一个元素为**标量**的集合C（一般是$\mathbb{R}$或$\mathbb{C}$）
- [x] 对加法和标量乘法是封闭的，满足以下公理：

$$
\begin{array}
{l}1.加法交换律：v+w=w+v\\
2.加法结合律：v+(w+x)=(v+w)+x\\
3.标量乘法结合律：(c_1c_2)v=c_1(c_2v)\\
4.加法幺元：v+0=v\\
5.乘法幺元：1v=v\\
6.加法逆元：v+(-v)=0\\
7.分配律1：c(v+w)=cv+cw,c\in C\\
8.分配律2：(c_1+c_2)v=c_1v+c_2v\\
\end{array}
$$

- 向量空间的标量乘法依赖于C，当需要指明时，我们说V是C上的向量空间，**$\mathbb{R}$上的向量空间称为实向量空间，$\mathbb{C}$上的向量空间称为复向量空间**。
- **张成（span）**：$S=\{v_1,v_2,\ldots,v_k\}\subset V$是$V$中k个向量的集合，则Span $\{v_1,v_2,\ldots,v_k\}$或者Span S定义为具有以下形式的向量的集合：

$$
c^1v_1+c^2v_2+\ldots+c^kv_k, c^i\in C
$$

- 也就是我们熟悉的$v_i$的**线性组合**。

- 向量空间$V$的基就是一组可以张成$V$的一组有序的线性无关的向量集合$\mathcal{B}=\{e_1,\ldots,e_k\}$。这里的“有序”强调了如果有一组有相同向量但顺序不同的向量集，则这两个基是不同的。**有限基中向量的个数即为有限维向量空间的维数**。

### 1.2 一些例子

- 例如，$\mathbb{R}^3$是我们熟悉的三维笛卡尔空间，$\mathbb{R}^4$是狭义相对论中的时空，$\mathbb{R}^n$在经典物理中常用来描述多粒子系统的位形空间。向量的定义是广义的，例如在一定区间平方可积的复值函数构成一个复向量空间$L^2([a,b])$，这里函数也是向量，事实上，下文会提到，$L^2([-a,a])$的基是$\{e^{i\frac{n\pi x}{a}}\}_{n\in\mathbb{Z}}$，是无限维的，**$L^2([-a,a])$是一个无限维希尔伯特空间（Hilbert space）**。
- 狭义上的向量只是一维矩阵（行向量、列向量），但在这里，容易从上述定义发现矩阵属于广义向量。向量空间有实向量空间和复向量空间之分，构成向量的元素是实数还是复数不是判断向量属于实向量空间还是复向量空间的依据，关键是看标量乘法中的c对实数成立还是复数成立，例如所有的厄密矩阵（转置共轭等于自身的矩阵）$H_{n}(\mathbb{C})$当被虚数i作用时，成为反厄密矩阵，不满足封闭性，尽管厄密矩阵非对角元可以是复数，**所有的厄密矩阵构成一个实向量空间**。
- 对于定义中的标量集C的元素为复数的复平面$\mathbb{C}$（complex plane）是可以由1张成，因为$z=z\cdot1\in\text{Span}\{1\}$，因此是一维的，对于定义中的标量集中元素为实数的复平面，记为$\mathbb{C}_R$，因为$z=a\cdot1+b\cdot i\in \text{Span}\{1,i\}$，因此$\mathbb{C}_R$是二维的。因此尽管向量集合$\mathbb{C}$、$\mathbb{C}_R$是一样的，但是因为标量集的不同而既可以是一维，也可以是二维，我们称$\mathbb{C}$为复数一维的（复向量空间）、实数二维的（实向量空间）。当我们在谈论复平面时，实际上更多是在讨论$\mathbb{C}_R$而不是$\mathbb{C}$。

### 1.3 分量（Components）

- 由于有基，向量空间$V$的任何向量$v$都可以用基$\mathcal{B}=\{e_i\}_{i=1...n}$进行展开：

$$
v=\sum_{i=1}^{n}v^{i}e_{i}
$$

- 我们称这些**$v^i$是$v$相对于$B$的分量**。进一步的，我们**可以把向量$v$用行向量（基是行向量）或者列向量（基是列向量）来表达**：

$$
[v]_{\mathcal B}=\begin{pmatrix}v^1\\ v^2\\.\\.\\.\\ v^n\end{pmatrix}
$$

$$
[v]_\mathcal B^T=(v^1,v^2,\ldots,v^n)
$$

- **向量独立于任意选择的基而存在，但是例如写成的行向量或者列向量的的表达式依赖于基的选择**，不同的基有不同的展开，所以对应的分量、行向量或列向量是不同的。
- $L^2([-a,a])$按照基$\{e^{i\frac{m\pi x}{a}}\}_{m\in\mathbb{Z}}$的展开：

$$
f=\sum\limits_{m=-\infty}^\infty c_me^{i\frac{mxx}{a}}
$$

- 上式其实就是典型的$f$的傅里叶级数，而$c_m$就是傅立叶系数，同时也是$f$相对于$\{e^{i\frac{m\pi x}{a}}\}_{m\in\mathbb{Z}}$的分量。

### 1.4 线性算子（Linear Operators）

- 向量空间$V$的一个线性算子是一个**从$V$映射到$V$自身**的**线性函数（线性变换）**$T$：

$$
T(cv+w)=cT(v)+T(w)
$$

- 我们有时把$Tv$写作$T(v)$。$V$上所有线性算子的集合构成一个空间，记为$\mathcal{L}(V)$。$n\times n$的实矩阵就是$\mathbb{R} ^n$上按照矩阵乘法作用的线性算子。因此$M_n(\mathbb{R})$或$M_n(\mathbb{C})$可以看成元素本身是线性算子的向量空间。在一个$\mathcal{L}(V)$空间，我们定义一个线性算子$\mathrm{ad}_{A}\in\mathcal{L}({\mathcal{L}}(V))$以该方式作用于$B$（对易子，commutator）：

$$
\operatorname{ad}_A(B)\equiv[A,B]=AB-BA
$$

- 上式中$A$在$\mathcal{L}(V)$上的作用称为伴随作用（adjoint action），或者称为伴随表示（adjoint representation）。
- 线性算子和矩阵是不同的东西。在一个有限维向量空间，选择基$\mathcal{B}=\{e_{i}\}_{i=1...n}$，那么线性算子$T$的作用可以由它在基上的作用决定：

$$
T(v)=T\left(\sum\limits_{i=1}^n v^i e_i\right)=\sum\limits_{i=1}^n v^i T(e_i)=\sum\limits_{i,j=1}^n v^i T_i^j e_j
$$

$$
T(e_{i})=\sum_{j=1}^{n}{T_{i}}^{j}e_{j}
$$

- ${T_i}^j$称为向量$T$相对于基$B$的分量，注意到${T_i}^{j}=T(e_i)^j$，即$T(e_i)^j$的第j个分量，我们有：

$$
[v]_{\mathcal B}=\begin{pmatrix}v^1\\ v^2\\.\\.\\ v^n\end{pmatrix},\ [T(v)]_{\mathcal B}=\begin{pmatrix}\sum_{i=1}^n v^i T_i^{1}\\ \sum_{i=1}^n v^i T_i^{2}\\.\\.\\.\\ \sum_{i=1}^n v^i T_i^{n}\end{pmatrix}
$$

- 这看起来像矩阵，事实上，我们我们可以定义$T$在基$B$上的矩阵，记为$[T]_{\mathcal{B}}$：

$$
[T(v)]_{\mathcal{B}}=[T]_{\mathcal{B}}[v]_{\mathcal{B}}
$$

$$
[T]_{\mathcal{B}}=\left(\begin{matrix}T_{1}^{~1}&T_{2}^{~1}&\ldots&T_{n}^{~1}\\ T_{1}^{~2}&T_{2}^{~2}&\ldots&T_{n}^{~2}\\.&.&.&.\\.&.&.&.\\.&.&.&.\\T_{1}^{~n}&T_{2}^{~n}&\ldots&T_{n}^{~n}\end{matrix}\right)
$$

- 当$[T]_{\mathcal{B}}$写成上式时，$T$的作用变成矩阵$[T]_{\mathcal{B}}$的乘法作用，此外，如果我们有两个线性算子$A$、$B$，我们定义其乘积（product）或复合（composition）为线性算子$AB$：

$$
(AB)(v)\equiv A(B(v))
$$

- $[AB]=[A][B]$。算子的分量成为了相应的矩阵。

### 1.5 对偶空间（Dual Spaces）

- 粗略地说，一个对偶向量是一个“吃掉”一个向量并“吐出”一个数的对象。准确地说，对于一个给定的向量空间$V$和标量集$C$，$V$上的一个对偶向量（或说线性泛函（linear functional））是$V$上一个**值属于标量集$C$的线性函数（C -valued linear function）$f$**，同样线性意味着：

$$
f(cv+w)=cf(v)+f(w)
$$

- 注意到$f(v)$和$f(w)$是标量，$f$将向量$cv+w$映射为标量$cf(v)+f(w)$，将向量的加法映射为标量的加法。$V$上对偶向量的集合称为$V$的对偶空间，并记为$V^*$，是标量集$C$上的向量空间。
- 举个例子。设$\{e_i\}$为$V$的一个基，因此任意的向量$v$可以写为$\sum_{i=1}^n v^ie_i\text{}$，所以我们可以通过以下方式定义一个对偶向量$e^i$：

$$
e^{i}(v)\equiv v^{i}
$$

- 也就是把$e^i$视为$v$的第i个分量$v_i $。显然，$e^{i}(v)$满足：

$$
e^{i}(e_{j})=\delta_{j}^{i}
$$

- 对偶向量$f$的一个关键性质是它完全由其作用在基向量上的值决定，根据线性性质，我们有：

$$
f(v)=f\left(\sum_{i=1}^n v^ie_i\right)=\sum_{i=1}^nv^if(e_i)\equiv\sum_{i=1}^nv^if_i
$$

- 我们定义了$f_{i}\equiv f(e_{i})$。

- 如果$V$是有限维的，维数为n，那么容易检验（两边同时作用于基向量$e_j$）：

$$
f(e_j)=1f_j=f_j,\ \sum\limits_{i=1}^nf_i e^i(e_j)=\sum\limits_{i=1}^nf_i\delta_{j}^{i}=f_j\\
f=\sum\limits_{i=1}^n f_i e^i
$$

- 从上式可以看出**$f_i$为$f$在$\{e^i\}$上的分量**。因为$f$是任意的，这意味着$e^i$张成$V^* $，利用$e^{i}(e_{j})=\delta_{j}^{i}$容易证明$e^i$是线性无关的，因此$\{e^i\}_{i=1...n}$就是对偶空间的基，我们有时称$e^i$是$e_i$的对偶。注意到$V$和$V^*$具有相同的维度。我们可以相对于基$\{e^i\}\equiv\mathcal{B}^*$将$f$写成分量的形式：

$$
[f]_{B^*}=\begin{pmatrix}f_1\\ f_2\\.\\.\\ f_n\end{pmatrix}
$$

- 借助于行向量$[f]^T_{B^*}$我们可以把$f(v)=\sum_{i=1}^nv^if_i$写为：

$$
f(v)=[f]_{\mathcal{B}^*}^T[v]_{\mathcal{B}}=[f]^T[v]
$$

- 在不引起歧义的情况下，上式最后一个等式去掉了表示基的下标。

- 在有限维，我们看到$V$中的基$\{e_i\}$诱导了$V^*$中的基$\{e^i\}$，但这在无限维并不是这样，在无限维，我们仍然有给定基的线性泛函，但这些线性泛函并不张成对偶空间。考虑$L^2([-a,a])\text{}$，我们定义$\{e^n\}_{n\in\mathbb{Z}}$为：

$$
e^n(f(x))\equiv\dfrac{1}{2a}\int_{-a}^a e^{-i\frac{n\pi x}{a}}f(x)dx
$$

- 这一定义满足$e^n(e^{i\frac{m\pi x}{a}})=\delta_n^m$，因此是$\{e^{i\frac{m\pi x}{a}}\}_{m\in\mathbb{Z}}$的对偶。但是有些线性泛函并不能写成$e^i $的线性组合，其中之一为狄拉克δ函数：

$$
\delta(f(x))\equiv f(0)
$$

## 2 张量

- 张量的三个重要属性

> (1) 秩：A function which eats a certain number of vectors (known as the **rank** r of the tensor) and produces a number. 
>
> (2) 多重线性：The distinguishing characteristic of a tensor is a special property called **multilinearity**, which means that it must be linear in each of its r arguments.
>
> (3) 分量：These values of the function on basis vectors are nothing but the familiar **components** of the tensor
>
> —*An Introduction to Tensors and Group Theory for Physicists*

### 2.1 初识张量

#### 2.1.1 列维—奇维塔（Levi–Civita）

- 按照前面提到的张量的属性，我们不妨尝试设计一个**rank-3 张量**，在设计的过程中理解张量是什么。设$\epsilon$"吃掉"了三个向量u、v、w（我在下文称其为（有序）基组，即基向量的有序组合），并产生了一个新的数$\epsilon\text{}(u,v,w)$，并且我们把$\epsilon\text{}(u,v,w)$设定为u、v、w张成的（有方向的）平行六面体的体积，我们能导出该体积为$\epsilon(u,v,w)\equiv(u\times v)\cdot w$

<div align="center"><img src="https://raw.githubusercontent.com/qjln/images/main/img/202303142218201.png" alt="image-20221204144107049" style="zoom:67%;" /></div>

- 为了让$\epsilon$确实成为一个张量，$\epsilon$必须要是**多重线性（multilinear）**的，这意味着：

$$
\begin{array}{c}\epsilon(u_1+cu_2,v,w)=\epsilon(u_1,v,w)+c\epsilon(u_2,v,w)\\ \epsilon(u,v_1+cv_2,w)=\epsilon(u,v_1,w)+c\epsilon(u,v_2,w)\\ \epsilon(u,v,w_1+cw_2)=\epsilon(u,v,w_1)+c\epsilon(u,v,w_2)\end{array}
$$

- 可以验证$\epsilon(u,v,w)\equiv(u\times v)\cdot w$满足上式

- 如果取u、v、w为基向量$e_1,e_2,e_3$，$e_1\times e_2=e_3,e_2 \times e_3=e_1,e_3 \times e_1=e_2$，可以推出：

$$
\epsilon(e_i,e_j,e_k)=\begin{cases}0&\text{unless i}\neq j\neq k\\ +1&\text{if}\{i,j,k\}=\{1,2,3\},\{2,3,1\},\text{or}\{3,1,2\}\\ -1&\text{if}\{i,j,k\}=\{3,2,1\},\{1,3,2\},\text{or}\{2,1,3\}\end{cases}
$$

- 按照上面的设定，我们可以定义张量$\epsilon$的**分量（components）**为$\epsilon_{ijk}\equiv\epsilon(e_i,e_j,e_k)$，而这正是物理中常见的Levi–Civita符号。

$$
\bar\epsilon(e_i,e_j,e_k)=\begin{cases}0&\text{unless i}\neq j\neq k\\ +1&\text{if}\{i,j,k\}=\{1,2,3\},\{2,3,1\},\text{or}\{3,1,2\}\\ -1&\text{if}\{i,j,k\}=\{3,2,1\},\{1,3,2\},\text{or}\{2,1,3\}\end{cases}
$$

- 事实上，我们上面设计的张量$\epsilon$被称为体积张量（volume tensor）或Levi–Civita张量（Levi–Civita tensor），**当基组以$e_1,e_2,e_3$组合时，Levi–Civita符号对应的就是Levi–Civita张量的分量，张量$\epsilon$的分量$\epsilon_{ijk}\equiv\epsilon(e_i,e_j,e_k)$就是给定一组基向量计算得到的张量的值**，在几何上，对应的是$e_i,e_j,e_k$张成的（有方向的）平行六面体的体积。

- 在最开始定义$\epsilon(u,v,w)\equiv(u\times v)\cdot w$时，我们并没有指定u是什么，v是什么，w是什么，$\epsilon$代表平行六面体体积这一特性不随基组的选择而变化，**张量独立于任何基向量存在，但其分量却是依赖基组的**。

#### 2.1.2 rank-2 张量

- 下面的讨论中，我们会认识到**一个张量就是一个多重线性函数（multilinear function）**。我们考虑rank-2 张量T，“吃掉”两个向量v、w，并产生一个数T(v,w)，前面提到，多重线性意味着：

$$
\begin{array}{c}T(v_1+cv_2,w)=T(v_1,w)+cT(v_2,w)\\ T(v,w_1+cw_2)=T(v,w_1)+cT(v,w_2)\end{array}
$$

- 多重线性带来一个重要的性质，如果我们用向量空间的坐标基底如$\hat{x},\hat{y},\hat{z}$来表示基向量，即：

$$
\begin{array}{c}v=v_x\mathbf{\hat{x}}+v_y\mathbf{\hat{y}}+v_z\mathbf{\hat{z}}\\ w=w_x\mathbf{\hat{x}}+w_y\mathbf{\hat{y}}+w_z\mathbf{\hat{z}}\end{array}
$$

- 那么我们能够得到

$$
\begin{aligned}T(v,w)&=T(v_x\hat{\mathbf{x}}+v_y\hat{\mathbf{y}}+v_z\hat{\mathbf{z}},w_x\hat{\mathbf{x}}+w_y\hat{\mathbf{y}}+w_z\hat{\mathbf{z}})\\ &=v_x T(\hat{\mathbf{x}},w_x\hat{\mathbf{x}}+w_y\hat{\mathbf{y}}+w_z\hat{\mathbf{z}})\\&+v_y T(\hat{\mathbf{y}},w_x\hat{\mathbf{x}}+w_y\hat{\mathbf{y}}+w_z\hat{\mathbf{z}})\\ &+v_z T(\hat{\mathbf{z}},w_x\hat{\mathbf{x}}+w_y\hat{\mathbf{y}}+w_z\hat{\mathbf{z}})\\
&=v_{x}w_{x}T(\hat{\mathbf{x}},\hat{\mathbf{x}})+v_{x}w_{y}T(\hat{\mathbf{x}},\hat{\mathbf{y}})+v_{x}w_{z}T(\hat{\mathbf{x}},\hat{\mathbf{z}})\\&+v_{y}w_{x}T(\hat{\mathbf{y}},\hat{\mathbf{x}})+v_{y}w_{y}T(\hat{\mathbf{y}},\hat{\mathbf{y}})+v_{y}w_{z}T(\hat{\mathbf{y}},\hat{\mathbf{z}})\\&+v_{z}w_{x}T(\hat{\mathbf{z}},\hat{\mathbf{x}})+v_{z}w_{y}T(\hat{\mathbf{z}},\hat{\mathbf{y}})+v_{z}w_{y}T(\hat{\mathbf{z}},\hat{\mathbf{y}})
\end{aligned}
$$

- 我们定义：

$$
T_{xx}\equiv T(\mathbf{\hat{x}},\mathbf{\hat{x}}), T_{xy}\equiv T(\mathbf{\hat{x}},\mathbf{\hat{y}}), T_{yx}\equiv T(\mathbf{\hat{y}},\mathbf{\hat{x}})
$$

- 则：

$$
\begin{aligned}T(v,w)&=v_x w_x T_{xx}+v_x w_y T_{xy}+v_x w_z T_{xz}\\&+v_y w_x T_{yx}+v_y w_y T_{yy} +v_y w_z T_{yz}\\&+v_z w_x T_{zx}+v_z w_y T_{zy}+v_z w_z T_{zz}\end{aligned}
$$

- 上式再次表明给定一组基向量，**张量的分量就是张量的函数值**。假定我们有一组新的基底向量，$\{\hat{\textbf{x}}',\hat{\textbf{y}}',\hat{\textbf{z}}'\}$，与旧基底的关系是：

$$
\begin{array}{c}\hat{\mathbf{x}}'=A_{x'x}\hat{\mathbf{x}}+A_{x'y}\hat{\mathbf{y}}+A_{x'z}\hat{\mathbf{z}}\\ \hat{\mathbf{y}}'=A_{y'x}\hat{\mathbf{x}}+A_{y'y}\hat{\mathbf{y}}+A_{y'z}\hat{\mathbf{z}}\\ \hat{\mathbf{z}}'=A_{z'x}\hat{\mathbf{x}}+A_{z'y}\hat{\mathbf{y}}+A_{z'z}\hat{\mathbf{z}}\end{array}
$$

- 我们重新计算张量的分量$\{T_{x^{\prime}x^{\prime}},T_{x^{\prime}y^{\prime}},T_{x^{\prime}z^{\prime}},\ldots\}$，例如：

$$
\begin{aligned}T_{x'x'}&=T(\hat{\mathbf{x}}',\hat{\mathbf{x}}')\\ &=T(A_{x'x}\hat{\mathbf{x}}+A_{x'y}\hat{\mathbf{y}}+A_{x'z}\hat{\mathbf{z}},A_{x'x}\hat{\mathbf{x}}+A_{x'y}\hat{\mathbf{y}}+A_{x'z}\hat{\mathbf{z}})\\
&=A_{x'x}A_{x'x}T_{xx}+A_{x'y}A_{x'x}T_{yx}+A_{x'z}A_{x'x}T_{zx}\\&+A_{x'x}A_{x'y}T_{xy}+  A_{x'y}A_{x'y}T_{yy}+A_{x'z}A_{x'y}T_{zy}\\&+A_{x'x}A_{x'z}T_{xz}+A_{x'y}A_{x'z}T_{yz}+A_{x'z}A_{x'z}T_{zz}\end{aligned}
$$

- 之后我们会学习到，采用爱因斯坦求和约定（Einstein summation convention），可以把上式写为：

$$
T_{i'j'}=A_{i'}^k A_{j'}^l T_{kl}
$$

- **张量可以用矩阵描述，但不是矩阵**，当我们把分量$\{T_{xx},T_{xy},T_{xz},\ldots\}$写成矩阵形式[T]：

$$
[T]=\begin{pmatrix}T_{xx}~T_{xy}~T_{xz}\\ T_{yx}~T_{yy}~T_{yz}\\ T_{zx}~T_{zy}~T_{zz}\end{pmatrix}
$$

- 则T(v,w)可以写为：

$$
T(v,w)=(v_x,v_y,v_z)\begin{pmatrix}T_{xx}T_{xy}T_{xz}\\ T_{yx}T_{yy}T_{yz}\\ T_{zx}T_{zy}T_{zz}\end{pmatrix}\begin{pmatrix}w_x\\ w_y\\ w_z\end{pmatrix}
$$

- 需要注意的是，这种张量与矩阵的关系依赖于基的选择，且写成矩阵形式[T]只是为了方便计算。**T是一个多重线性函数，而[T]是T在特定坐标系统中的表象（representation）**。
- 过去，矩阵、张量通常被视为将向量转化为向量的线性算子（算符），但我们这里张量的定义是“吃掉”向量，“吐”出数字。其实，对于rank-2 张量，这两种观点是等同的。假设我们有一个线性算子R，我们可以通过下式将R转化为rank-2 张量$T_R$：

$$
T_R(v,w)\equiv v\cdot Rw
$$

- 上式可以粗略理解为$T_R$把v、w“吃掉”，并“吐出”Rw在向量v方向上的分量。

- 计算$T_R$的分量，例如：

$$
\begin{aligned}(T_R)_{xx}&=T_R(\hat{\mathbf{x}},\hat{\mathbf{x}})\\ &=\hat{\mathbf{x}}\cdot R\hat{\mathbf{x}}\\ &=\hat{\mathbf{x}}\cdot(R_{xx}\hat{\mathbf{x}}+R_{yx}\hat{\mathbf{y}}+R_{zx}\hat{\mathbf{z}})\\ &=R_{xx}\end{aligned}
$$

- 我们发现张量$T_R$的分量$(T_R)_{xx}$和线性算子$R$的分量$R_{xx}$相等，具体的：

$$
T_R(v,w)=(v_x,v_y,v_z)\begin{pmatrix}R_{xx}R_{xy}R_{xz}\\ R_{yx}R_{yy}R_{yz}\\ R_{zx}R_{zy}R_{zz}\end{pmatrix}\begin{pmatrix}w_x\\ w_y\\ w_z\end{pmatrix}
$$

- 这个例子告诉，我们可以向三明治一样**将线性算子R夹在两个向量中间得到一个rank-2 张量。反过来，我们也可以将一个二阶张量T转化为一个线性算子$R_T$**：

$$
(R_T(v))_x\equiv T(\mathbf{\hat{x}},v)
$$

- 这**建立了rank-2 张量与线性算子之间的一一对应关系，两者因此等价**。

- 现在我们研究一下rank-2 转动惯量张量$\mathcal{I}$，角速度为$\boldsymbol{\omega}$，角动量为$\boldsymbol{L}$，动能为$KE$（kinetic energy），取基底为$\{\hat{\textbf{x}},\hat{\textbf{y}},\hat{\textbf{z}}\}$，我们可以认为$\mathcal{I}$是由下式定义的rank-2 张量：

$$
KE=\dfrac{1}{2}\mathcal{I}(\omega,\omega)
$$

$$
KE=\dfrac{1}{2}(\omega_x,\omega_y,\omega_z)\begin{pmatrix}\mathcal{I}_{xx}\mathcal{I}_{xy}\mathcal{I}_{xz}\\ \mathcal{I}_{yx}\mathcal{I}_{yy}\mathcal{I}_{yz}\\ \mathcal{I}_{zx}\mathcal{I}_{zy}\mathcal{I}_{zz}\end{pmatrix}\begin{pmatrix}\omega_x\\ \omega_y\\ \omega_z\end{pmatrix}
$$

#### 2.1.3 rank n

- 事实上，标量是rank 0张量（0个基向量），向量是rank 1张量（1个基向量），rank n张量在**d-维空间（d-dimensional space）**中是一个具有以下特性的对象：

- [x] 具有由n个指标标注的分量，每个指标可以从1到d中取，因此一共有$d^n$个分量。
- [x] 分量在特定的坐标变换下按照特定的方式变换。这是很重要的，因为物理量本质上不能因为坐标系统的选择而变化。

- 我们这里对张量随着基的变换的变换没有太多讨论，这并不影响我们导出张量的定义，但对理解张量特别重要，我可能会在后面的文章中学习分享。

### 2.2 更进一步的定义

#### 2.2.1 爱因斯坦求和约定（Einstein Summation Convention）

- 当表达式中一个指标同时出现上标和下标时，省略对该指标的求和符号，这样$v=\sum_{i=1}^{n}v^{i}e_{i}$变为$v=v^{i}e_{i}$，$Te_j=\sum_{i=1}^n {T_j}^ie_i$变为$Te_j={T_j}^ie_i$，被求和的指标称为哑标（dummy index），如这里的$i$，未被求和的指标被称为自由标（free index），如这里的$j$。在写任意基或坐标下的方程时，自由标只能在等式两边各出现一次，且在相同的位置（同时在上方或下方）。
- 当然爱因斯坦求和约定不止这些内容，其他的约定涉及更多概念时再引进即可。

#### 2.2.2 定义

- 前文，我们把rank n的张量定义为一个“吃掉”n个向量并产生一个数的多重线性函数，现在我们推广一下这个定义，一个张量“吃掉”r个向量和s个对偶向量（dual vectors），我们定义在向量空间V（r,s）型张量为一个C值函数（C -valued function，C是指标量集）T：

$$
\underbrace{V\times\cdots\times V}_{r\text{ times}}\times\underbrace{V^*\times\cdots\times V^*}_{s\text{ times}}
$$

- 对于每个变量（argument）满足线性，即多重线性，例如：

$$
\begin{array}{c}T(v_1+cw,v_2,\ldots,v_r,f_1,\ldots,f_s)\\ =T(v_1,\ldots,v_r,f_1,\ldots,f_s)\\ +cT(w,v_2,\ldots,f_1,\ldots,f_s)\end{array}
$$

- 可以把对偶向量视为(1,0)型张量。向量视为(0,1)型张量，如下：

$$
v(f)\equiv f(v)\text{ where }v\in V,f\in V^*
$$

- 线性算子可以被视为(1,1)型张量：

$$
A(v,f)\equiv f(Av)
$$

- 向量是(0,1)型张量、线性算子是(1,1)型张量并不是那么显然的，不过可以从上文中的讨论里直觉上感受这一观念。

- 标量可以视为(0,0)型张量。

- 向量空间$V$上(r,s)型张量，记为$T^r_s(V)$或$T^r_s$，形成一个向量空间，前文我们看到：

$$
\begin{aligned}
T(v,w)&=v_x w_x T_{xx}+v_x w_y T_{xy}+v_x w_z T_{xz}\\
&+v_y w_x T_{yx}+v_y w_y T_{yy} +v_y w_z T_{yz}\\
&+v_z w_x T_{zx}+v_z w_y T_{zy}+v_z w_z T_{zz}
\end{aligned}
$$

- 利用爱因斯坦求和约定，上式可以写为$T(v,w)=v^iw^jT_{ij}$，类似的，利用多重线性，我们有：

$$
\begin{aligned}T(v_1,\ldots,v_r,f_1,\ldots,f_s)&=v_1^{i_1}\ldots v_r^{i_r}f_{1j_1}\ldots f_{sj_s}T(e_{i_1},\ldots,e_{i_r},e^{j_1},\ldots,e^{j_s})\\ &\equiv v_1^{i_1}\ldots v_r^{i_r}f_{1j_1}\ldots f_{sj_s}{T_{i_1\ldots i_r}}^{j_1\ldots j_s}\end{aligned}
$$

- ${T_{i_{1}\ldots i_{r}}}^{j_{1}\ldots j_{s}}$为张量$T$相对于基$\{e_i\}_{i=1...n}$的分量：

$$
{T_{i_{1}\ldots i_{r}}}^{j_{1}\ldots j_{s}}\equiv T(e_{i_{1}},\ldots,e_{i_{r}},e^{j_{1}},\ldots,e^{j_{s}})
$$



> [1] JEEVANJEE N. An Introduction to Tensors and Group Theory for Physicists[M]. Cham: Springer International Publishing, 2015.
>
> [2]  ARFKEN G B, WEBER H J, HARRIS F E. Mathematical Methods for Physicists: A Comprehensive Guide[M]. 7th edition. Amsterdam ; Boston: Academic Press, 2012.

